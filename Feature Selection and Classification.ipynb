{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module to apply various Feature Selection Algorithms to get a subset of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.feature_selection import mutual_info_classif as mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.load(\"FINAL_scaled_data_sub1.npy\")\n",
    "y = np.load(\"label_sub1.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 329)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "#lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X, y)\n",
    "lsvc = LogisticRegression()\n",
    "lsvc.fit(X,y)\n",
    "\n",
    "#print lsvc.coef_\n",
    "lsvc.coef_ = np.array(lsvc.coef_)\n",
    "\n",
    "model = SelectFromModel(lsvc, prefit = True)\n",
    "X_new = model.transform(X)\n",
    "feature1 = X_new\n",
    "\n",
    "np.save(\"LogisticReg_data_selected\", X_new)\n",
    "print X_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual Information selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "relation = mf(X,y)\n",
    "\n",
    "index = []\n",
    "for i in range(740):\n",
    "    if relation[i] > 1.00e-01:\n",
    "        index.append(i)\n",
    "print len(index)\n",
    "X_mf = []\n",
    "for j in index:\n",
    "    X_mf.append(X[:,j])\n",
    "X_mf = np.transpose(np.array(X_mf))\n",
    "print X_mf.shape\n",
    "np.save(\"MF_data_selected\", X_mf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA, IncrementalPCA, KernelPCA\n",
    "\n",
    "\n",
    "kpca = KernelPCA(n_components = 10,kernel=\"rbf\", fit_inverse_transform=True, gamma=10)\n",
    "X4 = kpca.fit_transform(X)\n",
    "\n",
    "print X.shape\n",
    "print X4.shape\n",
    "\n",
    "np.save(\"PCA_data_selected\", X4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 Norm based Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X, y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_filtered4 = model.transform(X)\n",
    "print X_filtered4.shape\n",
    "\n",
    "np.save(\"L1_Norm_data_selected\", X_filtered4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree based Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "clf = ExtraTreesClassifier()\n",
    "clf = clf.fit(X, y)\n",
    "\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "X_filtered5 = model.transform(X)       \n",
    "\n",
    "print X_filtered5.shape\n",
    "np.save(\"Tree_based_data_selected.npy\", X_filtered5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data after Selection for classification  :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 329)\n",
      "(720, 2)\n",
      "(720, 10)\n",
      "(720, 301)\n",
      "(720, 51)\n",
      "(720, 740)\n"
     ]
    }
   ],
   "source": [
    "X1 = np.load(\"LogisticReg_data_selected.npy\")\n",
    "X2 = np.load(\"L1_Norm_data_selected.npy\")\n",
    "X3 = np.load(\"PCA_data_selected.npy\")\n",
    "X4 = np.load(\"Tree_based_data_selected.npy\")\n",
    "X5 = np.load(\"MF_data_selected.npy\")\n",
    "X6 = np.load(\"FINAL_scaled_data_sub1.npy\")\n",
    "print X1.shape\n",
    "print X2.shape\n",
    "print X3.shape\n",
    "print X4.shape\n",
    "print X5.shape\n",
    "print X6.shape\n",
    "X = [] \n",
    "X.append(X1)\n",
    "X.append(X2)\n",
    "X.append(X3)\n",
    "X.append(X4)\n",
    "X.append(X5)\n",
    "X.append(X6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 2220)\n",
      "(720,)\n"
     ]
    }
   ],
   "source": [
    "X_all = np.load(\"data_scaled_all_channels.npy\")\n",
    "X_all = X_all[range(720),:]\n",
    "y_all = np.load(\"outfile_label.npy\")\n",
    "y_all = y_all[range(720)]\n",
    "print X_all.shape\n",
    "print y_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of motor Imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bci-hci-lab/anaconda2/envs/saleeg/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/bci-hci-lab/anaconda2/envs/saleeg/lib/python2.7/site-packages/sklearn/naive_bayes.py:432: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = - 0.5 * np.sum(np.log(2. * np.pi * self.sigma_[i, :]))\n",
      "/home/bci-hci-lab/anaconda2/envs/saleeg/lib/python2.7/site-packages/sklearn/naive_bayes.py:434: RuntimeWarning: invalid value encountered in divide\n",
      "  (self.sigma_[i, :]), 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation result\n",
      "0.401388888889\n",
      "0.61049382716\n",
      "normal spliting result\n",
      "0.555555555556\n",
      "cross validation result\n",
      "0.277777777778\n",
      "0.27299382716\n",
      "normal spliting result\n",
      "0.244444444444\n",
      "cross validation result\n",
      "0.25\n",
      "0.25\n",
      "normal spliting result\n",
      "0.238888888889\n",
      "cross validation result\n",
      "0.351388888889\n",
      "0.495061728395\n",
      "normal spliting result\n",
      "0.466666666667\n",
      "cross validation result\n",
      "0.355555555556\n",
      "0.486111111111\n",
      "normal spliting result\n",
      "0.444444444444\n",
      "cross validation result\n",
      "0.327777777778\n",
      "0.508641975309\n",
      "normal spliting result\n",
      "0.422222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "for x in X:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=10)\n",
    "\n",
    "    gnb = GaussianNB()\n",
    "    y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "    y_cross = cross_validate(gnb, x, y, cv =10)\n",
    "    print (\"cross validation result\" )\n",
    "    print np.mean(y_cross[\"test_score\"])\n",
    "    print np.mean(y_cross[\"train_score\"])\n",
    "    print (\"normal spliting result\")\n",
    "    print metrics.accuracy_score(y_test, y_pred, normalize=True, sample_weight=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation result\n",
      "0.327777777778\n",
      "0.508641975309\n",
      "normal spliting result\n",
      "0.611111111111\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.25, random_state=10)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "y_cross = cross_validate(gnb, x, y, cv =10)\n",
    "print (\"cross validation result\" )\n",
    "print np.mean(y_cross[\"test_score\"])\n",
    "print np.mean(y_cross[\"train_score\"])\n",
    "print (\"normal spliting result\")\n",
    "print metrics.accuracy_score(y_test, y_pred, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Decision Tree Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation result\n",
      "1. test:\n",
      "0.320833333333\n",
      "2. train\n",
      "1.0\n",
      "normal spliting result\n",
      "0.422222222222\n",
      "cross validation result\n",
      "1. test:\n",
      "0.297222222222\n",
      "2. train\n",
      "1.0\n",
      "normal spliting result\n",
      "0.272222222222\n",
      "cross validation result\n",
      "1. test:\n",
      "0.25\n",
      "2. train\n",
      "0.25\n",
      "normal spliting result\n",
      "0.238888888889\n",
      "cross validation result\n",
      "1. test:\n",
      "0.319444444444\n",
      "2. train\n",
      "1.0\n",
      "normal spliting result\n",
      "0.488888888889\n",
      "cross validation result\n",
      "1. test:\n",
      "0.319444444444\n",
      "2. train\n",
      "1.0\n",
      "normal spliting result\n",
      "0.505555555556\n",
      "cross validation result\n",
      "1. test:\n",
      "0.315277777778\n",
      "2. train\n",
      "1.0\n",
      "normal spliting result\n",
      "0.433333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "for x in X:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=40)\n",
    "\n",
    "    modelDecisionTree = tree.DecisionTreeClassifier()\n",
    "    modelDecisionTree = modelDecisionTree.fit(X_train, y_train)\n",
    "    y_cross = cross_validate(modelDecisionTree, x, y, cv =10)\n",
    "    print (\"cross validation result\" )\n",
    "    print (\"1. test:\")\n",
    "    print np.mean(y_cross[\"test_score\"])\n",
    "    print (\"2. train\")\n",
    "    print np.mean(y_cross[\"train_score\"])\n",
    "    print (\"normal spliting result\")\n",
    "\n",
    "    y_test_pred = modelDecisionTree.predict(X_test)\n",
    "\n",
    "    print metrics.accuracy_score(y_test, y_test_pred, normalize=True, sample_weight=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation result\n",
      "1. test:\n",
      "0.325\n",
      "2. train:\n",
      "1.0\n",
      "normal spliting result\n",
      "0.638888888889\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.25, random_state=40)\n",
    "\n",
    "modelDecisionTree = tree.DecisionTreeClassifier()\n",
    "modelDecisionTree = modelDecisionTree.fit(X_train, y_train)\n",
    "y_cross = cross_validate(modelDecisionTree, x, y, cv =10)\n",
    "print (\"cross validation result\" )\n",
    "print (\"1. test:\")\n",
    "print np.mean(y_cross[\"test_score\"])\n",
    "print (\"2. train:\")\n",
    "print np.mean(y_cross[\"train_score\"])\n",
    "print (\"normal spliting result\")\n",
    "\n",
    "y_test_pred = modelDecisionTree.predict(X_test)\n",
    "\n",
    "print metrics.accuracy_score(y_test, y_test_pred, normalize=True, sample_weight=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stocastic Gradient Decent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bci-hci-lab/anaconda2/envs/saleeg/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation result\n",
      "1. test:\n",
      "0.463888888889\n",
      "2. train\n",
      "0.741512345679\n",
      "normal spliting result\n",
      "0.533333333333\n",
      "cross validation result\n",
      "1. test:\n",
      "0.2625\n",
      "2. train\n",
      "0.267901234568\n",
      "normal spliting result\n",
      "0.283333333333\n",
      "cross validation result\n",
      "1. test:\n",
      "0.25\n",
      "2. train\n",
      "0.25\n",
      "normal spliting result\n",
      "0.238888888889\n",
      "cross validation result\n",
      "1. test:\n",
      "0.406944444444\n",
      "2. train\n",
      "0.691512345679\n",
      "normal spliting result\n",
      "0.533333333333\n",
      "cross validation result\n",
      "1. test:\n",
      "0.320833333333\n",
      "2. train\n",
      "0.493981481481\n",
      "normal spliting result\n",
      "0.527777777778\n",
      "cross validation result\n",
      "1. test:\n",
      "0.386111111111\n",
      "2. train\n",
      "0.679475308642\n",
      "normal spliting result\n",
      "0.55\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "for x in X:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y , test_size=0.25, random_state=40)\n",
    "\n",
    "    modelSGD = SGDClassifier(loss=\"hinge\", penalty=\"l1\")\n",
    "    modelSGD.fit(X_train, y_train)\n",
    "    y_cross = cross_validate(modelSGD, x, y, cv =10)\n",
    "    print (\"cross validation result\" )\n",
    "    print (\"1. test:\")\n",
    "    print np.mean(y_cross[\"test_score\"])\n",
    "    print (\"2. train\")\n",
    "    print np.mean(y_cross[\"train_score\"])\n",
    "    print (\"normal spliting result\")\n",
    "    y_test_pred = modelSGD.predict(X_test)\n",
    "\n",
    "    print metrics.accuracy_score(y_test, y_test_pred, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation result\n",
      "1. test:\n",
      "0.465277777778\n",
      "2. train:\n",
      "0.99274691358\n",
      "normal spliting result\n",
      "0.727777777778\n",
      "cross validation result\n",
      "1. test:\n",
      "0.315277777778\n",
      "2. train:\n",
      "0.309413580247\n",
      "normal spliting result\n",
      "0.316666666667\n",
      "cross validation result\n",
      "1. test:\n",
      "0.25\n",
      "2. train:\n",
      "0.25\n",
      "normal spliting result\n",
      "0.238888888889\n",
      "cross validation result\n",
      "1. test:\n",
      "0.391666666667\n",
      "2. train:\n",
      "0.946604938272\n",
      "normal spliting result\n",
      "0.672222222222\n",
      "cross validation result\n",
      "1. test:\n",
      "0.363888888889\n",
      "2. train:\n",
      "0.581327160494\n",
      "normal spliting result\n",
      "0.5\n",
      "cross validation result\n",
      "1. test:\n",
      "0.338888888889\n",
      "2. train:\n",
      "1.0\n",
      "normal spliting result\n",
      "0.638888888889\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "for x in X:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=40)\n",
    "\n",
    "    modelSVM = svm.LinearSVC()\n",
    "    modelSVM.fit(X_train,y_train)\n",
    "    y_cross = cross_validate(modelSVM, x, y, cv =10)\n",
    "    print (\"cross validation result\" )\n",
    "    print (\"1. test:\")\n",
    "    print np.mean(y_cross[\"test_score\"])\n",
    "    print (\"2. train:\")\n",
    "    print np.mean(y_cross[\"train_score\"])\n",
    "    print (\"normal spliting result\")\n",
    "\n",
    "    y_test_pred = modelSVM.predict(X_test)\n",
    "\n",
    "    print metrics.accuracy_score(y_test, y_test_pred, normalize=True, sample_weight=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation result\n",
      "1. test:\n",
      "0.584722222222\n",
      "2. train:\n",
      "0.999845679012\n",
      "normal spliting result\n",
      "0.833333333333\n"
     ]
    }
   ],
   "source": [
    "    X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.25, random_state=40)\n",
    "\n",
    "    modelSVM = svm.LinearSVC()\n",
    "    modelSVM.fit(X_train,y_train)\n",
    "    y_cross = cross_validate(modelSVM, X_all, y_all, cv =10)\n",
    "    print (\"cross validation result\" )\n",
    "    print (\"1. test:\")\n",
    "    print np.mean(y_cross[\"test_score\"])\n",
    "    print (\"2. train:\")\n",
    "    print np.mean(y_cross[\"train_score\"])\n",
    "    print (\"normal spliting result\")\n",
    "\n",
    "    y_test_pred = modelSVM.predict(X_test)\n",
    "\n",
    "    print metrics.accuracy_score(y_test, y_test_pred, normalize=True, sample_weight=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation result\n",
      "1. test:\n",
      "0.583333333333\n",
      "2. train:\n",
      "1.0\n",
      "normal spliting result\n",
      "0.822222222222\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.25, random_state=40)\n",
    "\n",
    "modelSVM = svm.LinearSVC()\n",
    "modelSVM.fit(X_train,y_train)\n",
    "y_cross = cross_validate(modelSVM, X_all, y_all, cv =10)\n",
    "print (\"cross validation result\" )\n",
    "print (\"1. test:\")\n",
    "print np.mean(y_cross[\"test_score\"])\n",
    "print (\"2. train:\")\n",
    "print np.mean(y_cross[\"train_score\"])\n",
    "print (\"normal spliting result\")\n",
    "\n",
    "y_test_pred = modelSVM.predict(X_test)\n",
    "\n",
    "print metrics.accuracy_score(y_test, y_test_pred, normalize=True, sample_weight=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.633333333333\n",
      "0.203333333333\n",
      "0.246666666667\n",
      "0.59\n",
      "0.23\n",
      "0.596666666667\n"
     ]
    }
   ],
   "source": [
    "for x in X:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=40)\n",
    "    modelSVM = svm.NuSVC()\n",
    "    modelSVM.fit(X_train,y_train)\n",
    "\n",
    "    y_test_pred = modelSVM.predict(X_test)\n",
    "\n",
    "    print metrics.accuracy_score(y_test, y_test_pred, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0.368055555556\n",
      "0.883333333333\n",
      "\n",
      "\n",
      "0.297222222222\n",
      "0.261111111111\n",
      "\n",
      "\n",
      "0.25\n",
      "0.261111111111\n",
      "\n",
      "\n",
      "0.383333333333\n",
      "0.866666666667\n",
      "\n",
      "\n",
      "0.345833333333\n",
      "0.688888888889\n",
      "\n",
      "\n",
      "0.333333333333\n",
      "0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "for x in X:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=40)\n",
    "\n",
    "    modelknn = KNeighborsClassifier(n_neighbors=3)\n",
    "    modelknn.fit(X_train,y_train)\n",
    "    y_cross = cross_validate(modelknn, x, y, cv =10)\n",
    "    \"\"\"\n",
    "    print (\"cross validation result\" )\n",
    "    print (\"1. test:\")\n",
    "    print (y_cross[\"test_score\"])\n",
    "    print (\"2. train\")\n",
    "    print (y_cross[\"train_score\"])\"\"\"\n",
    "    print (\"\\n\")\n",
    "    print np.mean(y_cross[\"test_score\"])\n",
    "    \n",
    " \n",
    "    y_test_pred = modelknn.predict(X_test)\n",
    "\n",
    "    print metrics.accuracy_score(y_test, y_test_pred, normalize=True, sample_weight=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0.559722222222\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "    # knn\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.25, random_state=40)\n",
    "\n",
    "    modelknn = KNeighborsClassifier(n_neighbors=3)\n",
    "    modelknn.fit(X_train,y_train)\n",
    "    y_cross = cross_validate(modelknn, X_all, y_all, cv =10)\n",
    "    \"\"\"\n",
    "    print (\"cross validation result\" )\n",
    "    print (\"1. test:\")\n",
    "    print (y_cross[\"test_score\"])\n",
    "    print (\"2. train\")\n",
    "    print (y_cross[\"train_score\"])\"\"\"\n",
    "    print (\"\\n\")\n",
    "    print np.mean(y_cross[\"test_score\"])\n",
    "    \n",
    " \n",
    "    y_test_pred = modelknn.predict(X_test)\n",
    "\n",
    "    print metrics.accuracy_score(y_test, y_test_pred, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.62\n",
      "0.39\n",
      "0.246666666667\n",
      "0.6\n",
      "0.303333333333\n"
     ]
    }
   ],
   "source": [
    "for x in X:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=40)\n",
    "    modelSVM = svm.LinearSVC()\n",
    "    modelSVM.fit(X_train,y_train)\n",
    "\n",
    "    y_test_pred = modelSVM.predict(X_test)\n",
    "\n",
    "    print metrics.accuracy_score(y_test, y_test_pred, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34\n",
      "0.288333333333\n",
      "0.248333333333\n",
      "0.3375\n",
      "0.344166666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for x in X:\n",
    "    modelRF = RandomForestClassifier(n_estimators=5, max_depth=None,min_samples_split=3, random_state=10)\n",
    "    scores = cross_val_score(modelRF, x, y)\n",
    "    print scores.mean()                             \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.330833333333\n",
      "0.29\n",
      "0.388333333333\n",
      "0.344166666667\n",
      "0.368333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "for x in X:\n",
    "    modelET = ExtraTreesClassifier(n_estimators=10, max_depth=None,min_samples_split=2, random_state=0)\n",
    "    scores = cross_val_score(modelET, x, y)\n",
    "    print scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37\n",
      "0.293333333333\n",
      "0.2425\n",
      "0.37\n",
      "0.3175\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "for x in X:\n",
    "    modelAda = AdaBoostClassifier(n_estimators=100)\n",
    "    scores = cross_val_score(modelAda,x,y)\n",
    "    print scores.mean()                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Tree Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59\n",
      "0.36\n",
      "0.29\n",
      "0.623333333333\n",
      "0.63\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "for x in X:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=40)\n",
    "\n",
    "    clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0).fit(X_train, y_train)\n",
    "    print clf.score(X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Class AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.516666666667\n",
      "0.363333333333\n",
      "0.256666666667\n",
      "0.526666666667\n",
      "0.493333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "for x in X:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=40)\n",
    "\n",
    "    bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                             algorithm=\"SAMME\",\n",
    "                             n_estimators=200)\n",
    "\n",
    "    bdt.fit(X_train, y_train)\n",
    "\n",
    "    y_test_pred = bdt.predict(X_test)\n",
    "\n",
    "    print metrics.accuracy_score(y_test, y_test_pred, normalize=True, sample_weight=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.233333333333\n",
      "0.24\n",
      "0.236666666667\n",
      "0.233333333333\n",
      "0.24\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "for x in X:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=40)\n",
    "\n",
    "    modelMLP = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "    modelMLP.fit(X_train, y_train)\n",
    "\n",
    "    y_test_pred = modelMLP.predict(X_test)\n",
    "\n",
    "    print metrics.accuracy_score(y_test, y_test_pred, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bci-hci-lab/anaconda2/envs/saleeg/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:532: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LatentDirichletAllocation' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-a1cc65eb28a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodelLDA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0my_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelLDA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LatentDirichletAllocation' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "for x in X:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.25, random_state=40)\n",
    "\n",
    "    modelLDA = LDA()\n",
    "\n",
    "    modelLDA.fit(X_train, y_train)\n",
    "\n",
    "    y_test_pred = modelLDA.predict(X_test)\n",
    "\n",
    "    print metrics.accuracy_score(y_test, y_test_pred, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0006142 ,  0.01422066],\n",
       "       [ 0.00030224,  0.0062485 ],\n",
       "       [ 0.00081061,  0.01698939],\n",
       "       ..., \n",
       "       [ 0.00583448,  0.12693771],\n",
       "       [ 0.00166921,  0.02382961],\n",
       "       [ 0.00152293,  0.03716975]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [saleeg]",
   "language": "python",
   "name": "Python [saleeg]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
